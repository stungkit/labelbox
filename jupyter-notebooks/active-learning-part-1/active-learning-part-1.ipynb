{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning: Speed up training data cycles with uncertainty sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1 of a series highlighting Labelbox as a data engine powering your machine learning system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software dependencies\n",
    "This notebook can be run using the following [Dockerfile](./Dockerfile) and [requirements.txt](./requirements.txt)\n",
    "\n",
    "Build the Docker image locally:\n",
    "\n",
    "```\n",
    "docker build -t active-learning-part-1 .\n",
    "```\n",
    "\n",
    "Launch the image with access to this notebook from within the current directory:\n",
    "```\n",
    "docker run -it -p 8888:8888 -v \\\n",
    "${PWD}:/usr/src/app -w /usr/src/app active-learning-part-1 \\\n",
    "jupyter notebook --ip 0.0.0.0 --no-browser  --allow-root\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset details\n",
    "\n",
    "Sentiment analysis on tweets taken from Twitter is a well-explored and tractable nlp problem.  We take a random 8,000 tweets from the [`sentiment140`](https://www.kaggle.com/kazanova/sentiment140) dataset that are already classified as positive (`0`) or negative (`4`) sentiment.\n",
    "\n",
    "The derived [8000 random tweets csv](./data/training_8000_shuffled.csv) is included for reference and was created by sorting randomly and then taking the first 8000 rows:\n",
    "\n",
    "```\n",
    "$sort -R training.1600000.processed.noemoticon.csv > training.1600000.processed.noemoticon.csv.shuffled\n",
    "$head -8000 training.1600000.processed.noemoticon.csv.shuffled > training_8000_shuffled.csv\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Ingest into Labelbox\n",
    "First, we need to label a subset of data with Labelbox. To do so, we need to:\n",
    "1. [Create a project](https://labelbox.com/docs/python-api/create-first-project)\n",
    "2. Create and upload our dataset\n",
    "3. [Configure the Labelbox text classification editor](https://labelbox.com/docs/nlp/text-classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "from collections import defaultdict\n",
    "from enum import Enum\n",
    "from itertools import chain, islice\n",
    "import json\n",
    "import os\n",
    "from typing import Callable, Dict, List, Tuple\n",
    "\n",
    "from labelbox import Client, Dataset, LabelingFrontend, Project, DataRow\n",
    "from labelbox import schema\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.legend import Legend\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "import subprocess\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELBOX_API_KEY = '<LABELBOX_API_KEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading our 8000 tweets into a DataFrame, taking 800 for our validation set and 7200 for our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "RANDOM_SEED = 123\n",
    "DATA_DIR = 'data'\n",
    "\n",
    "def load_non_weather_data():\n",
    "    data = pd.read_csv(\n",
    "        filepath_or_buffer=os.path.join(DATA_DIR, 'training_8000_shuffled.csv'),\n",
    "        names=[\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"],\n",
    "        encoding='ISO-8859-1'\n",
    "    )\n",
    "    data.rename(columns=\n",
    "        {\n",
    "            'target': 'sentiment',\n",
    "            'ids': 'id'\n",
    "        }, inplace=True\n",
    "    )\n",
    "    # 0 is positive\n",
    "    # 4 is negative in the original dataset, use 1 for clarity\n",
    "    data.sentiment = data.sentiment.map({0: 0, 4: 1}).values\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def train_val_split(df, test_frac: float):\n",
    "    test_rows = df.sample(frac=test_frac, random_state=RANDOM_SEED)\n",
    "    df['split'] = df.id.apply(lambda row: 'test' if row in test_rows.id.values else 'train')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT_DF = load_non_weather_data()\n",
    "SENTIMENT_DF = train_val_split(SENTIMENT_DF, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "# labelbox setup names\n",
    "PROJECT_NAME = 'tweet_sentiment_demo'\n",
    "DATASET_NAME = 'tweet_sentiment_demo'\n",
    "LABELING_FRONTEND_NAME = \"Binary sentiment editor\"\n",
    "\n",
    "\n",
    "def maybe_create_project(project_name: str) -> schema.project.Project:\n",
    "    '''Creates project if it does not already exist, otherwise fetches.\n",
    "    \n",
    "    NOTE: we assume there is only one project with a given\n",
    "    project name.  this is not guaranteed, but sufficient\n",
    "    for a tutorial.\n",
    "    \n",
    "    '''\n",
    "    client = Client(LABELBOX_API_KEY)\n",
    "    projects = client.get_projects(where=Project.name == project_name)\n",
    "    try:\n",
    "        project = next(iter(projects))\n",
    "    except StopIteration:\n",
    "        project = client.create_project(name=project_name)\n",
    "    return project\n",
    "\n",
    "\n",
    "def sentiment_df_to_json_rows(dataframe: pd.core.frame.DataFrame) -> Dict[str, str]:\n",
    "    ''''''\n",
    "    return json.loads(\n",
    "        dataframe.rename(\n",
    "            columns={'id': 'external_id', 'text': 'row_data'}\n",
    "        )[['external_id', 'row_data']].to_json(orient='records'))\n",
    "\n",
    "\n",
    "def maybe_create_sentiment_dataset(\n",
    "        dataset_name: str,\n",
    "        project_name: str,\n",
    "        dataframe: pd.core.frame.DataFrame) -> schema.dataset.Dataset:\n",
    "    '''Creates our sentiment dataset with 80k datarows if it does not already exist, otherwise fetches.\n",
    "    '''    \n",
    "    client = Client(LABELBOX_API_KEY)\n",
    "    project = maybe_create_project(project_name)\n",
    "    datasets = client.get_datasets(where=Dataset.name == DATASET_NAME)\n",
    "    try:\n",
    "        dataset = next(iter(datasets))\n",
    "        \n",
    "        def attach_dataset(project_id: str, dataset_id: str) -> None:\n",
    "            response = client.execute(f'''\n",
    "                mutation AttachDataset{{\n",
    "                    updateProject( \n",
    "                        where:{{ \n",
    "                            id: \"{project_id}\"\n",
    "                        }},\n",
    "                        data:{{\n",
    "                            datasets: {{ \n",
    "                                connect: {{ \n",
    "                                    id: \"{dataset_id}\"\n",
    "                                }}\n",
    "                            }}\n",
    "                        }}\n",
    "                    ){{\n",
    "                        id \n",
    "                    }}\n",
    "                }}\n",
    "            ''')\n",
    "\n",
    "        attach_dataset(project.uid, dataset.uid)\n",
    "        \n",
    "    except StopIteration:\n",
    "        dataset = client.create_dataset(name=DATASET_NAME, projects=project)\n",
    "\n",
    "    try:\n",
    "        next(iter(dataset.data_rows()))\n",
    "    except StopIteration:\n",
    "        task = dataset.create_data_rows(sentiment_df_to_json_rows(dataframe))\n",
    "        task.wait_till_done()\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def update_with_uid(\n",
    "        dataframe: pd.core.frame.DataFrame,\n",
    "        dataset: schema.dataset.Dataset) -> pd.core.frame.DataFrame:\n",
    "    \"\"\"Add uid column for tracking labelbox's id of the same datarow in our dataframe.\n",
    "    \n",
    "    Args:\n",
    "        df: dataframe to augment\n",
    "        project_name: project name for dataset\n",
    "        dataset_name: name for dataset\n",
    "        \n",
    "    \"\"\"    \n",
    "    external_uid_map = {\n",
    "        int(data_row.external_id): data_row.uid\n",
    "        for data_row in dataset.data_rows()\n",
    "    }\n",
    "    dataframe['uid'] = dataframe.id.map(external_uid_map)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def create_labeling_frontend() -> str:\n",
    "    '''Creates a labeling frontend and returns its id.'''\n",
    "    client = Client(LABELBOX_API_KEY)\n",
    "    response = client.execute('''\n",
    "        mutation CreateLabelingFrontend {\n",
    "          createLabelingFrontend(data: {\n",
    "            description: \"Classify sentiment as positive or negative\",\n",
    "            iframe_url_path: \"https://classification.labelbox.com\",\n",
    "            name: $name\n",
    "          }){\n",
    "            id\n",
    "          }\n",
    "        }\n",
    "    ''', {'name': LABELING_FRONTEND_NAME})\n",
    "    return json.loads(response)['data']['CreateLabelingFrontend']['id']\n",
    "\n",
    "    \n",
    "\n",
    "def maybe_create_ontology(project_name: str) -> None:\n",
    "    '''Creates/grabs ontology for sentiment annotation.\n",
    "    \n",
    "    1. Sets up ontology for binary sentiment classification.\n",
    "    2. Sets labeling frontend using the classification iframe.\n",
    "    3. Links these with the given project.\n",
    "    \n",
    "    '''\n",
    "    client = Client(LABELBOX_API_KEY)\n",
    "    project = maybe_create_project(project_name)\n",
    "    ontology = '''\n",
    "        {\n",
    "            \"tools\": [],\n",
    "            \"classifications\": [\n",
    "                {\n",
    "                    \"name\": \"Sentiment\",\n",
    "                    \"instructions\": \"Is this tweet primarily positive or negative in sentiment?\",\n",
    "                    \"type\": \"radio\",\n",
    "                    \"options\": [\n",
    "                        {\n",
    "                            \"value\": 0,\n",
    "                            \"label\": \"Negative\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"value\": 1,\n",
    "                            \"label\": \"Positive\"\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    '''\n",
    "    frontends = client.get_labeling_frontends(where=LabelingFrontend.name == LABELING_FRONTEND_NAME)\n",
    "    try:\n",
    "        frontend = next(iter(frontends))\n",
    "    except StopIteration:\n",
    "        frontend_id = create_labeling_frontend()\n",
    "        frontends = client.get_labeling_frontends(\n",
    "            where=LabelingFrontend.id == frontend_id)\n",
    "        frontend = next(iter(frontends))\n",
    "    project.setup(frontend, ontology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a project named `PROJECT_NAME` with a dataset named `DATASET_NAME` using our API key, `LABELBOX_API_KEY`.  After uploading our 8000 tweets to Labelbox, we update our DataFrame with the [DataRow.uid](https://labelbox.com/docs/python-api/api-reference#data_row) to keep track of uid's given by Labelbox.  To finish project setup, we link it with an labeling frontend and ontology specifically for [Text Classification](https://labelbox.com/docs/nlp/text-classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = maybe_create_sentiment_dataset(dataset_name=DATASET_NAME, project_name=PROJECT_NAME, dataframe=SENTIMENT_DF)\n",
    "update_with_uid(SENTIMENT_DF, dataset)\n",
    "maybe_create_ontology(PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a labeling frontend set up, we can proceed to provide classification annotations for some of our tweets.\n",
    "![](./images/editor.png)\n",
    "Since our dataset already includes sentiment classifications, we can proceed as if we already annotated 100 tweets and train a preliminary model on these 100 tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model\n",
    "Thanks to advances in deep learning for NLP, we do not have train a language model from scratch.  We use a [distilled](https://en.wikipedia.org/wiki/Knowledge_distillation) version of [BERT](https://github.com/google-research/bert): [DistilBERT](https://arxiv.org/abs/1910.01108) to generate embeddings of our tweets.  We then pool these embeddings together and treat them as features for a logistic regression to learn sentiment.\n",
    "\n",
    "Note: Depending on the hardware this is run on, embedding 8000 tweets may take 15-20 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\", cache_dir='model_dir')\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\", cache_dir='model_dir')\n",
    "\n",
    "\n",
    "def encode_text(text):\n",
    "    '''Embed text with DistilBERT and return average pool.\n",
    "    \n",
    "    Note: YMMV with average pool vs max pool.  average pool was just chosen for simplicity.\n",
    "    '''\n",
    "    input_ids = torch.tensor([tokenizer.encode(text)])\n",
    "    return model(input_ids)[0].mean(1)[0].detach().numpy()\n",
    "\n",
    "\n",
    "def add_encoded(df: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    '''Add features encoded by DistilBERT and an average pool as a column.'''\n",
    "    df['encoded_text'] = df.text.apply(encode_text)\n",
    "    return df\n",
    "\n",
    "\n",
    "def train_model(train: pd.core.frame.DataFrame) -> LogisticRegression:\n",
    "    '''Trains logistic regression model over given training data.'''\n",
    "    model = LogisticRegression(solver=\"liblinear\")\n",
    "    model.fit(list(train.encoded_text.values), list(train.sentiment.values))\n",
    "    return model\n",
    "\n",
    "\n",
    "def eval_model(model: LogisticRegression, test: pd.core.frame.DataFrame) -> float:\n",
    "    '''Calculates AUC of the ROC of the trained model on given test data.\n",
    "    \n",
    "    https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve\n",
    "    '''\n",
    "    # auc score entire over test split\n",
    "    roc = roc_auc_score(\n",
    "        list(test.sentiment.values),\n",
    "        model.predict_proba(list(test.encoded_text.values))[:,1])\n",
    "    return roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT_DF = add_encoded(SENTIMENT_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = SENTIMENT_DF[SENTIMENT_DF.split == 'train']\n",
    "test = SENTIMENT_DF[SENTIMENT_DF.split == 'test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "We begin our first iteration by prioritizing any 100 datarows for human annotation **via [Queue customization](https://labelbox.com/docs/api/queue-customization#setting_queue_prioritization) in Labelbox**.\n",
    "\n",
    "1. Set priority of 100 datarows to `1`\n",
    "2. Set priority of the remainder datarows to `2`\n",
    "\n",
    "Note: Priority for all datarows should be set, [otherwise the queue may default to lexicographical resolution of priority](https://labelbox.com/docs/api/queue-customization#prioritization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#collapse\n",
    "def fetch_labeling_parameter_overrides(project_name: str) -> List:\n",
    "    '''Fetches all datarows with labeling parameter overrides in a project.'''\n",
    "    project_id = maybe_create_project(project_name).uid\n",
    "    client = Client(LABELBOX_API_KEY)\n",
    "\n",
    "    overrides = []\n",
    "    override = True\n",
    "    while override:\n",
    "        response = client.execute(\n",
    "            f'''\n",
    "            query pullLabelingParameters{{\n",
    "              project(where: {{id: \"{project_id}\"}}) {{\n",
    "                labelingParameterOverrides{{\n",
    "                  id\n",
    "                  priority\n",
    "                }}\n",
    "              }}\n",
    "            }}\n",
    "            '''\n",
    "        )\n",
    "        override = json.loads(response)['data']['project']['labelingParameterOverrides']\n",
    "        overrides.extend(override)\n",
    "    return overrides\n",
    "    \n",
    "\n",
    "def prioritize(project_name: str, dataset_name: str, uids: List[str]) -> None:\n",
    "    '''Prioritizes given uids for labeling and deprioritizes all other.\n",
    "    \n",
    "    NOTE: We have to deprioritize so that we don't rely on queue rebuilding to\n",
    "    avoid default lexicographical sorting.\n",
    "    > When setting queue prioritization on an active queue, and without the queue rebuilding,\n",
    "      the given data rows will have their priority updated, and if thereâ€™s a collision\n",
    "      (as in above, where two data rows have a priority of 1), they will be ordered lexicographically.\n",
    "      \n",
    "    https://labelbox.com/docs/api/queue-customization#setting_queue_prioritization\n",
    "    \n",
    "    '''\n",
    "    project_id = maybe_create_project(project_name).uid\n",
    "    dataset = maybe_create_sentiment_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        project_name=project_name,\n",
    "        dataframe=SENTIMENT_DF)\n",
    "    \n",
    "    priority_data_rows = (\n",
    "        f'{{dataRow: {{id: \"{uid}\"}}, priority: 1, numLabels: 1}}'\n",
    "        for uid in uids\n",
    "    )\n",
    "    rest_data_rows = (\n",
    "        f'{{dataRow: {{id: \"{data_row.uid}\"}}, priority: 2, numLabels: 1}}'\n",
    "        for data_row in dataset.data_rows()\n",
    "        if data_row.uid not in uids\n",
    "    )\n",
    "    data_rows = chain(priority_data_rows, rest_data_rows)\n",
    "    client = Client(LABELBOX_API_KEY)\n",
    "\n",
    "    def batches(iterable, size):\n",
    "        iterator = iter(iterable)\n",
    "        for first in iterator:\n",
    "            yield chain([first], islice(iterator, size - 1))\n",
    "\n",
    "    for batch in batches(data_rows, size=999):\n",
    "        response = client.execute(\n",
    "            f'''\n",
    "            mutation setLabelingParameterOverrides {{\n",
    "              project(where: {{ id: \"{project_id}\" }}) {{\n",
    "                setLabelingParameterOverrides(data: [\n",
    "                    {','.join(batch)}\n",
    "                ]) {{\n",
    "                  success\n",
    "                }}\n",
    "              }}\n",
    "            }}\n",
    "            '''\n",
    "        )\n",
    "        assert not response.get('errors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prioritize(PROJECT_NAME, DATASET_NAME, SENTIMENT_DF.head(100).uid.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When these datarows are labeled, we would export them via [bulk export](https://labelbox.com/docs/python-api/labels#export_labels) or [webhooks](https://labelbox.com/docs/api/webhooks).  However, for this walkthrough, we can just take the first 100 from the already labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_budget = 100\n",
    "labeled_training_data = train[:annotation_budget]\n",
    "model = train_model(labeled_training_data)\n",
    "roc = eval_model(model, test)\n",
    "print(f'ROC: {roc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty sampling\n",
    "\n",
    "We will employ a fairly straightforward definition of model uncertainty: one minus the largest posterior probability of our model.  The intuition here is: given the the highest posterior probability is the model's prediction, we take the remaining probability left until the model would have been 100% certain as the uncertainty.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertainty_score(\n",
    "        rows: pd.core.frame.DataFrame,\n",
    "        model: LogisticRegression) -> float:\n",
    "    '''Returns uncertainty of the model on given data.'''\n",
    "    return 1 - model.predict_proba(list(rows.encoded_text)).max(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the subsequent batches of annotations, we will pick top 100 datarows for which the model is the most uncertain.  For demonstration's sake, we work with our already labeled dataset.  In reality, one would continue employing the above outlined prioritization via [Queue customization](https://labelbox.com/docs/api/queue-customization#setting_queue_prioritization) in Labelbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "def naive_sampler(\n",
    "        sample: pd.core.frame.DataFrame,\n",
    "        train: pd.core.frame.DataFrame,\n",
    "        num: int, _) -> pd.core.frame.DataFrame:\n",
    "    '''Returns the next number of datarows that have not been trained on.'''\n",
    "    untrained = train[~train.index.isin(sample.index)]\n",
    "    return pd.concat([sample, untrained.head(num)])\n",
    "\n",
    "def uncertainty_sampler(\n",
    "        sample: pd.core.frame.DataFrame,\n",
    "        train: pd.core.frame.DataFrame,\n",
    "        num: int,\n",
    "        model: LogisticRegression) -> pd.core.frame.DataFrame:\n",
    "    '''Returns the top number of most uncertain datarows.'''\n",
    "    \n",
    "    untrained = train[~train.index.isin(sample.index)]\n",
    "    def uncertainty_sampling(\n",
    "            rows: pd.core.frame.DataFrame,\n",
    "            num: int,\n",
    "            model: LogisticRegression) -> pd.core.frame.DataFrame:\n",
    "        temp_df = rows.copy()\n",
    "        temp_df['uncertainty'] = uncertainty_score(rows, model)\n",
    "        temp_df = temp_df.sort_values('uncertainty', ascending=False)\n",
    "        return temp_df[:num]\n",
    "\n",
    "    return pd.concat([sample, uncertainty_sampling(untrained, num, model)])\n",
    "\n",
    "\n",
    "def batch_roc(\n",
    "        train: pd.core.frame.DataFrame,\n",
    "        batches: List[int],\n",
    "        sampling_method: str) -> List[float]:\n",
    "    '''Returns ROC metric for every addition to the training data.\n",
    "    \n",
    "    The sampling_method will dictate how new data is selected\n",
    "    for labeling and inclusion into training data.\n",
    "\n",
    "    '''\n",
    "    SAMPLING_METHODS = {\n",
    "        'naive': naive_sampler,\n",
    "        'uncertainty': uncertainty_sampler\n",
    "    }\n",
    "\n",
    "    rocs = []\n",
    "    batch_size = batches[1] - batches[0]\n",
    "    sample = train[:batch_size]\n",
    "    \n",
    "    for _ in batches:\n",
    "        model = train_model(sample)\n",
    "        roc = eval_model(model, test)\n",
    "        #roc = eval_model(model, train)\n",
    "        rocs.append(roc)\n",
    "        sample = SAMPLING_METHODS[sampling_method](sample, train, batch_size, model)\n",
    "    return rocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "We compare uncertainty sampling against naive sampling where random data is selected at every iteration until all training data is labeled and trained over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "batch_size = 100\n",
    "batches = np.arange(100, len(train), batch_size)\n",
    "\n",
    "naive_rocs = batch_roc(train, batches, 'naive')\n",
    "uncertainty_rocs = batch_roc(train, batches, 'uncertainty')\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "lines = [\n",
    "    ax.plot(batches, uncertainty_rocs, '-', color='blue', label='uncertainty sampling'),\n",
    "    ax.plot(batches, naive_rocs, '--', color='black', label='random sampling'),\n",
    "]\n",
    "ax.set_xlabel('# of labeled data in training set')\n",
    "ax.set_ylabel('ROC on test set')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/roc_uncertainty_random_7200_800.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model trained with training examples chosen by uncertainty sampling is able to reach asymptotic performance with around 3000 annotations.  The model trained by naive random sampling requires a bit over 5000 examples to perform equally well.  Not only does this minimize the number of assets that require human annotation, it minimizes the number of examples the model has to be trained with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "[Queue customization](https://labelbox.com/docs/api/queue-customization#setting_queue_prioritization) in Labelbox is an incredibly simple way to start using active learning.  By prioritizing certain datarows for annotation, machine learning systems can achieve their goals with less annotation cost and fewer training cycles.  In many cases, the datarows that a model is uncertain of are also often more engaging to annotate and more important to review, allowing the human components of your machine learning system to spend their time on high impact decisions.\n",
    "\n",
    "\n",
    "## Practical considerations\n",
    "\n",
    "Modern neural networks are deeper and datasets are larger; retraining may neither be ideal nor necessary.  Active learning is also a useful tool for transfer learning or finetuning frameworks.  Tasks beyond classification can also benefit: image segmentation, named entity recognition, etc.  We encourage you to seek domain specific literature for inspiration.\n",
    "\n",
    "For example, there are other ways of measuring uncertainty, such as classification entropy or classification margin.  Or you may wish to differentiate between [epistemic and aleatoric uncertainty](https://arxiv.org/abs/1909.00218).  In fact, **uncertainty sampling** is far from the only way of surfacing informative examples.\n",
    "\n",
    "For ensemble-based approaches, disagreement sampling may be more useful, surfacing examples where the ensemble is highly disagreeable.\n",
    "\n",
    "For datasets with a long tail of rare examples, diversity sampling proposes representative examples for prioritization.\n",
    "\n",
    "\n",
    "## Next Steps\n",
    "The example covered here uses uncertainty sampling to address a binary sentiment classification problem.\n",
    "\n",
    "**How might queue customization speed up your training iteration cycles?**\n",
    "\n",
    "1. Prioritizing rare examples?\n",
    "1. Prioritizing complicated examples?\n",
    "1. [Tell us more; reach out to us!](mailto:research@labelbox.com)\n",
    "\n",
    "**How can Labelbox help?**\n",
    "\n",
    "1. Surface informative datarows for your dataset for training or review?\n",
    "1. Aid exploration of your dataset based on metadata associated with each datarow?\n",
    "1. [Tell us more; reach out to us!](mailto:research@labelbox.com)\n",
    "\n",
    "We would love to hear more about them!\n",
    "\n",
    "**[Sign up to get notified for Part 2](link) in the near future on what Labelbox can do with your model predictions!**\n",
    "\n",
    "\n",
    "## Additional Reading\n",
    "1. [Settles, Burr.  *Active Learning Literature Survey*.](http://burrsettles.com/pub/settles.activelearning.pdf)\n",
    "1. [modAL: A modular active learning framework for Python3.](https://modal-python.readthedocs.io/en/latest/index.html#)\n",
    "1. [Building the Software 2.0 Stack (Andrej Karpathy)](https://www.youtube.com/watch?v=y57wwucbXR8)\n",
    "1. [Deep Learning: State of the Art (2020)](https://lexfridman.com/files/slides/2020_01_06_deep_learning_state_of_the_art.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(zip(batches, uncertainty_rocs, naive_rocs), columns=['num_labels', 'ROC_uncertainty', 'ROC_naive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('./data/ROC_values.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
